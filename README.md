# ğŸ§  Autonomous Hill Climb Racing AI using YOLOv8 + DQN

This project builds an AI agent that autonomously plays the 2D game *Hill Climb Racing* using reinforcement learning and computer vision. The agent perceives the game screen via screenshots, detects objects using YOLOv8, and interacts using keyboard simulation with PyAutoGUI.

---

## ğŸš€ Features

- ğŸ¯ Real-time object detection using **YOLOv8**
- ğŸ¤– Reinforcement Learning agent based on **Deep Q-Network (DQN)**
- âŒ¨ï¸ Game control using **PyAutoGUI** (no internal APIs)
- ğŸ”„ Auto restart and crash recovery
- ğŸ“Š TensorBoard logging for training progress
- ğŸ’¾ Model saving & evaluation script for demonstrations

---

## ğŸ—‚ï¸ Project Structure

```
hillclimb_rl/
â”œâ”€â”€ env.py           # Custom RL environment
â”œâ”€â”€ dqn_agent.py     # Deep Q-Network logic
â”œâ”€â”€ main.py          # Training script
â”œâ”€â”€ evaluate.py      # Run the trained agent
â”œâ”€â”€ utils.py         # Helper functions (screenshot, detection, etc.)
â”œâ”€â”€ model/           # Saved model checkpoints
â”œâ”€â”€ runs/            # Logs for training/evaluation
â”œâ”€â”€ datasets/        # YOLO training data
â””â”€â”€ README.md        # This file
```

---

## ğŸ§ª Setup Instructions

### âœ… 1. Clone the repository
```bash
git clone https://github.com/your-username/hillclimb-rl.git
cd hillclimb-rl
```

### âœ… 2. Install dependencies
```bash
pip install -r requirements.txt
```

### âœ… 3. Download YOLOv8 weights (or use your trained model)
Place your trained YOLOv8 model at:
```
runs/detect/train/weights/best.pt
```

### âœ… 4. Run Training
```bash
python main.py
```

### âœ… 5. Run Evaluation (demo play)
```bash
python evaluate.py
```

---

## ğŸ® Game Requirements

- Install Hill Climb Racing on Windows
- Set game window resolution to 800x480
- Place game window at top-left (0,0)
- Ensure itâ€™s **active and focused** during play

---

## ğŸ“Š Results

| Metric         | Value     |
|----------------|-----------|
| YOLO mAP@0.5   | 95.3%     |
| Avg. Reward    | +10.5     |
| Max Distance   | 1134 px   |
| Fuel Pickups   | 6â€“7 per run |
| Crash Rate     | â†“ to 19% |

---

## ğŸ“š Future Improvements

- PPO or A3C policy optimization
- GUI overlay with reward/live Q-values
- Transfer to other games (e.g., Mario, Dino)
- Model distillation for mobile use

---

## ğŸ‘¨â€ğŸ’» Author

**Podupuganti Akshay**  
B.Tech, Software Engineering â€“ 2024-25  
Contact: [your_email@example.com]

---

## ğŸ“„ License

This project is open-source for educational and research purposes. Commercial use prohibited without permission.